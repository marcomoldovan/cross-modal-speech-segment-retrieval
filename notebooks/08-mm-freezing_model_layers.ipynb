{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from typing import Optional, Union, Tuple\n",
    "from transformers import BertModel\n",
    "from transformers.models.bert.modeling_bert import BertPreTrainedModel, BertEmbeddings, BertEncoder, BertPooler\n",
    "from transformers.models.hubert.modeling_hubert import HubertPreTrainedModel, HubertFeatureEncoder, HubertFeatureProjection, HubertEncoder, HubertModel\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPastAndCrossAttentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-4_H-128_A-2 were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertModel.from_pretrained('google/bert_uncased_L-4_H-128_A-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_module(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.word_embeddings.weight\n",
      "torch.Size([30522, 128])\n",
      "True\n",
      "\n",
      "embeddings.position_embeddings.weight\n",
      "torch.Size([512, 128])\n",
      "True\n",
      "\n",
      "embeddings.token_type_embeddings.weight\n",
      "torch.Size([2, 128])\n",
      "True\n",
      "\n",
      "embeddings.LayerNorm.weight\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "embeddings.LayerNorm.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.0.attention.self.query.weight\n",
      "torch.Size([128, 128])\n",
      "True\n",
      "\n",
      "encoder.layer.0.attention.self.query.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.0.attention.self.key.weight\n",
      "torch.Size([128, 128])\n",
      "True\n",
      "\n",
      "encoder.layer.0.attention.self.key.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.0.attention.self.value.weight\n",
      "torch.Size([128, 128])\n",
      "True\n",
      "\n",
      "encoder.layer.0.attention.self.value.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.0.attention.output.dense.weight\n",
      "torch.Size([128, 128])\n",
      "True\n",
      "\n",
      "encoder.layer.0.attention.output.dense.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.0.attention.output.LayerNorm.weight\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.0.attention.output.LayerNorm.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.0.intermediate.dense.weight\n",
      "torch.Size([512, 128])\n",
      "True\n",
      "\n",
      "encoder.layer.0.intermediate.dense.bias\n",
      "torch.Size([512])\n",
      "True\n",
      "\n",
      "encoder.layer.0.output.dense.weight\n",
      "torch.Size([128, 512])\n",
      "True\n",
      "\n",
      "encoder.layer.0.output.dense.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.0.output.LayerNorm.weight\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.0.output.LayerNorm.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.1.attention.self.query.weight\n",
      "torch.Size([128, 128])\n",
      "True\n",
      "\n",
      "encoder.layer.1.attention.self.query.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.1.attention.self.key.weight\n",
      "torch.Size([128, 128])\n",
      "True\n",
      "\n",
      "encoder.layer.1.attention.self.key.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.1.attention.self.value.weight\n",
      "torch.Size([128, 128])\n",
      "True\n",
      "\n",
      "encoder.layer.1.attention.self.value.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.1.attention.output.dense.weight\n",
      "torch.Size([128, 128])\n",
      "True\n",
      "\n",
      "encoder.layer.1.attention.output.dense.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.1.attention.output.LayerNorm.weight\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.1.attention.output.LayerNorm.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.1.intermediate.dense.weight\n",
      "torch.Size([512, 128])\n",
      "True\n",
      "\n",
      "encoder.layer.1.intermediate.dense.bias\n",
      "torch.Size([512])\n",
      "True\n",
      "\n",
      "encoder.layer.1.output.dense.weight\n",
      "torch.Size([128, 512])\n",
      "True\n",
      "\n",
      "encoder.layer.1.output.dense.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.1.output.LayerNorm.weight\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.1.output.LayerNorm.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.2.attention.self.query.weight\n",
      "torch.Size([128, 128])\n",
      "True\n",
      "\n",
      "encoder.layer.2.attention.self.query.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.2.attention.self.key.weight\n",
      "torch.Size([128, 128])\n",
      "True\n",
      "\n",
      "encoder.layer.2.attention.self.key.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.2.attention.self.value.weight\n",
      "torch.Size([128, 128])\n",
      "True\n",
      "\n",
      "encoder.layer.2.attention.self.value.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.2.attention.output.dense.weight\n",
      "torch.Size([128, 128])\n",
      "True\n",
      "\n",
      "encoder.layer.2.attention.output.dense.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.2.attention.output.LayerNorm.weight\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.2.attention.output.LayerNorm.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.2.intermediate.dense.weight\n",
      "torch.Size([512, 128])\n",
      "True\n",
      "\n",
      "encoder.layer.2.intermediate.dense.bias\n",
      "torch.Size([512])\n",
      "True\n",
      "\n",
      "encoder.layer.2.output.dense.weight\n",
      "torch.Size([128, 512])\n",
      "True\n",
      "\n",
      "encoder.layer.2.output.dense.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.2.output.LayerNorm.weight\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.2.output.LayerNorm.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.3.attention.self.query.weight\n",
      "torch.Size([128, 128])\n",
      "True\n",
      "\n",
      "encoder.layer.3.attention.self.query.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.3.attention.self.key.weight\n",
      "torch.Size([128, 128])\n",
      "True\n",
      "\n",
      "encoder.layer.3.attention.self.key.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.3.attention.self.value.weight\n",
      "torch.Size([128, 128])\n",
      "True\n",
      "\n",
      "encoder.layer.3.attention.self.value.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.3.attention.output.dense.weight\n",
      "torch.Size([128, 128])\n",
      "True\n",
      "\n",
      "encoder.layer.3.attention.output.dense.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.3.attention.output.LayerNorm.weight\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.3.attention.output.LayerNorm.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.3.intermediate.dense.weight\n",
      "torch.Size([512, 128])\n",
      "True\n",
      "\n",
      "encoder.layer.3.intermediate.dense.bias\n",
      "torch.Size([512])\n",
      "True\n",
      "\n",
      "encoder.layer.3.output.dense.weight\n",
      "torch.Size([128, 512])\n",
      "True\n",
      "\n",
      "encoder.layer.3.output.dense.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.3.output.LayerNorm.weight\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "encoder.layer.3.output.LayerNorm.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n",
      "pooler.dense.weight\n",
      "torch.Size([128, 128])\n",
      "True\n",
      "\n",
      "pooler.dense.bias\n",
      "torch.Size([128])\n",
      "True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    # if param.requires_grad:\n",
    "        print(name)\n",
    "        print(param.shape)\n",
    "        print(param.requires_grad)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters = lambda model : {'requires_grad':sum(p.numel() for p in model.parameters() if p.requires_grad)/1e6,\n",
    "                                   'does_not_require_grad':sum(p.numel() for p in model.parameters() if not p.requires_grad)/1e6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'requires_grad': 4.782464, 'does_not_require_grad': 0.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertEmbeddings\n",
      "BertEncoder\n",
      "0\n",
      "BertPooler\n"
     ]
    }
   ],
   "source": [
    "train_layers = 1\n",
    "\n",
    "for child in model.children():\n",
    "    print(child._get_name())\n",
    "    if isinstance(child, BertEmbeddings):\n",
    "        freeze_whole_model(child)\n",
    "    elif isinstance(child, )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'requires_grad': 0.793088, 'does_not_require_grad': 3.989376}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'embeddings'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\marco\\Google Drive\\Projects\\Cross-Modal Speech Segment Retrieval\\cross-modal-speech-segment-retrieval\\notebooks\\08-mm-freezing_model_layers.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marco/Google%20Drive/Projects/Cross-Modal%20Speech%20Segment%20Retrieval/cross-modal-speech-segment-retrieval/notebooks/08-mm-freezing_model_layers.ipynb#ch0000004?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m child \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mnamed_children():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/marco/Google%20Drive/Projects/Cross-Modal%20Speech%20Segment%20Retrieval/cross-modal-speech-segment-retrieval/notebooks/08-mm-freezing_model_layers.ipynb#ch0000004?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(child\u001b[39m.\u001b[39;49membeddings)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marco/Google%20Drive/Projects/Cross-Modal%20Speech%20Segment%20Retrieval/cross-modal-speech-segment-retrieval/notebooks/08-mm-freezing_model_layers.ipynb#ch0000004?line=2'>3</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(child, BertEmbeddings):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/marco/Google%20Drive/Projects/Cross-Modal%20Speech%20Segment%20Retrieval/cross-modal-speech-segment-retrieval/notebooks/08-mm-freezing_model_layers.ipynb#ch0000004?line=3'>4</a>\u001b[0m         \u001b[39mprint\u001b[39m(child)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'embeddings'"
     ]
    }
   ],
   "source": [
    "for child in model.named_children():\n",
    "    print(child.embeddings)\n",
    "    if isinstance(child, BertEmbeddings):\n",
    "        print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union, Tuple\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import HubertModel, BertModel, PretrainedConfig\n",
    "from transformers.models.hubert.modeling_hubert import HubertPreTrainedModel, HubertFeatureEncoder, HubertFeatureProjection, HubertEncoder\n",
    "from transformers.models.bert.modeling_bert import BertPreTrainedModel, BertEmbeddings, BertEncoder, BertPooler\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPastAndCrossAttentions\n",
    "\n",
    "class ModelOutputs:\n",
    "    def __init__(\n",
    "        self,\n",
    "        speech_pooler_output: torch.Tensor = None,\n",
    "        speech_model_hidden_states: torch.Tensor = None,\n",
    "        speech_model_attentions: torch.Tensor = None,\n",
    "        text_pooler_output: torch.Tensor = None,\n",
    "        text_model_hidden_states: torch.Tensor = None,\n",
    "        text_model_attentions: torch.Tensor = None,\n",
    "        multimodal_model_hidden_states: torch.Tensor = None,\n",
    "        multimodal_model_attentions: torch.Tensor = None,\n",
    "    ):\n",
    "        # speech encoder outputs\n",
    "        self.speech_pooler_output = speech_pooler_output\n",
    "        self.speech_model_hidden_states = speech_model_hidden_states\n",
    "        self.speech_model_attentions = speech_model_attentions\n",
    "        # text encoder outputs\n",
    "        self.text_pooler_output = text_pooler_output\n",
    "        self.text_model_hidden_states = text_model_hidden_states\n",
    "        self.text_model_attentions = text_model_attentions\n",
    "        # multimodal encoder outputs\n",
    "        self.multimodal_model_hidden_states = multimodal_model_hidden_states\n",
    "        self.multimodal_model_attentions = multimodal_model_attentions\n",
    "\n",
    "\n",
    "    \n",
    "class BertEmbeddingsWrapper(BertPreTrainedModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config\n",
    "        ):\n",
    "        super().__init__(config)\n",
    "        \n",
    "        self.embeddings = BertEmbeddings(config)\n",
    "        \n",
    "        self.post_init()\n",
    "    \n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        token_type_ids: Optional[torch.LongTensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        past_key_values_length: int = 0,\n",
    "        ) -> torch.Tensor:\n",
    "        \n",
    "        return self.embeddings(input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\n",
    "    \n",
    "    \n",
    "    \n",
    "class BertEncoderWrapper(BertPreTrainedModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config\n",
    "        ):\n",
    "        super().__init__(config)\n",
    "        \n",
    "        self.encoder = BertEncoder(config)\n",
    "        \n",
    "        self.post_init()\n",
    "    \n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "        output_hidden_states: Optional[bool] = False,\n",
    "        return_dict: Optional[bool] = True,\n",
    "        ) -> Union[Tuple[torch.Tensor], BaseModelOutputWithPastAndCrossAttentions]:\n",
    "        \n",
    "        encoder_outputs = self.encoder(\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            head_mask,\n",
    "            encoder_hidden_states,\n",
    "            encoder_attention_mask,\n",
    "            past_key_values,\n",
    "            use_cache,\n",
    "            output_attentions,\n",
    "            output_hidden_states,\n",
    "            return_dict,\n",
    "        )\n",
    "        \n",
    "        return encoder_outputs\n",
    "    \n",
    "    \n",
    "    \n",
    "class BertPoolerWrapper(BertPreTrainedModel):\n",
    "    def __init__(\n",
    "        self, \n",
    "        config):\n",
    "        super().__init__(config)\n",
    "        \n",
    "        self.pooler = BertPooler(config)\n",
    "        \n",
    "        self.post_init()\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        return self.pooler(hidden_states)\n",
    "    \n",
    "    \n",
    "\n",
    "class HubertConvFeatureExtractorWrapper(HubertPreTrainedModel):\n",
    "    # named HubertFeatureEncoder on huggingface\n",
    "    def __init__(\n",
    "        self,\n",
    "        config\n",
    "        ):\n",
    "        super().__init__(config)\n",
    "        \n",
    "        self.feature_extractor = HubertFeatureEncoder(config)\n",
    "        \n",
    "        self.post_init()\n",
    "    \n",
    "    \n",
    "    def forward(self, input_values: torch.Tensor) -> torch.Tensor:\n",
    "        return self.feature_extractor(input_values)\n",
    "    \n",
    "    \n",
    "class FeatureProjection(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        speech_config, \n",
    "        text_config\n",
    "        ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(speech_config.conv_dim[0])\n",
    "        self.projection = nn.Linear(speech_config.conv_dim[0], text_config.hidden_size)\n",
    "        self.dropout = nn.Dropout(speech_config.feat_proj_dropout)    \n",
    "    \n",
    "    \n",
    "    def forward(self):\n",
    "        # non-projected hidden states are needed for quantization\n",
    "        norm_hidden_states = self.layer_norm(hidden_states)\n",
    "        hidden_states = self.projection(norm_hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        return hidden_states, norm_hidden_states\n",
    "    \n",
    "    \n",
    "    \n",
    "class HubertFeatureProjectionWrapper(HubertPreTrainedModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config\n",
    "        ):\n",
    "        super().__init__(config)\n",
    "        \n",
    "        self.feature_projection = HubertFeatureProjection(config)\n",
    "        \n",
    "        self.post_init()\n",
    "    \n",
    "    \n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        return self.feature_projection(hidden_states)\n",
    "    \n",
    "    \n",
    "\n",
    "class HubertEncoderWrapper(HubertPreTrainedModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config\n",
    "        ):\n",
    "        super().__init__(config)\n",
    "        \n",
    "        self.encoder = HubertEncoder(config)\n",
    "        \n",
    "        self.post_init()\n",
    "    \n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask=None,\n",
    "        output_attentions=False,\n",
    "        output_hidden_states=True,\n",
    "        return_dict=True):\n",
    "        \n",
    "        outputs = self.encoder(\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            output_attentions,\n",
    "            output_hidden_states,\n",
    "            return_dict,\n",
    "        )\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    \n",
    "    \n",
    "class HubertPooler(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size_in: int = 768,\n",
    "        hidden_size_out: int = 768,\n",
    "        ):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.dense = nn.Linear(hidden_size_in, hidden_size_out)\n",
    "        self.activation = nn.Tanh()\n",
    "    \n",
    "    \n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size, sequence_length, _ = hidden_states.size()\n",
    "        attention_mask = torch.ones(batch_size, sequence_length)\n",
    "        \n",
    "        # ? Does torch.mean(outputs['last_hidden_state'], dim=1) also work?\n",
    "        \n",
    "        output_vectors = []\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()\n",
    "        sum_embeddings = torch.sum(hidden_states * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        output_vectors.append(sum_embeddings / sum_mask)\n",
    "        output_vector = torch.cat(output_vectors, 0)\n",
    "        \n",
    "        if self.config.speech_output_pooling_strategy == 'pooling_layer':\n",
    "            output_vector = self.activation(self.dense(output_vector))\n",
    "        \n",
    "        return output_vector\n",
    "\n",
    "\n",
    "\n",
    "class HubertModelWithoutFeatureEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pretrained_model: str = 'ntu-spml/distilhubert',\n",
    "        hidden_size_in: int = 768,\n",
    "        hidden_size_out: int = 768\n",
    "        ):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.projector = HubertFeatureProjectionWrapper.from_pretrained(pretrained_model)\n",
    "        self.encoder = HubertEncoderWrapper.from_pretrained(pretrained_model)\n",
    "        self.pooler = HubertPooler(hidden_size_in, hidden_size_out)\n",
    "        \n",
    "    \n",
    "    def forward(self, speech_features: torch.Tensor) -> torch.Tensor:\n",
    "        outputs = self.projector(speech_features)\n",
    "        outputs = self.encoder(outputs)\n",
    "        outputs = self.pooler(outputs.last_hidden_state)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    \n",
    "\n",
    "class HubertModelWithPooler(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pretrained_model: str = 'ntu-spml/distilhubert',\n",
    "        pooler_output_size: int = 768,\n",
    "        ):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.hubert = HubertModel.from_pretrained(pretrained_model)\n",
    "        self.pooler = HubertPooler(self.hubert.config.hidden_size, pooler_output_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, speech_features: torch.Tensor) -> torch.Tensor:\n",
    "        outputs = self.hubert(speech_features)\n",
    "        outputs = self.pooler(outputs.last_hidden_state)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    \n",
    "    \n",
    "class BiEncoderSpeechTextModelWithoutFeatureEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pretrained_speech_model: str = 'ntu-spml/distilhubert',\n",
    "        pretrained_text_model: str = 'google/bert_uncased_L-2_H-768_A-12',\n",
    "        ):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.text_model = BertModel.from_pretrained(pretrained_text_model)\n",
    "        self.speech_model = HubertModelWithoutFeatureEncoder(pretrained_speech_model, hidden_size_out=self.text_model.config.hidden_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, speech, text):\n",
    "        #TODO outsource this to before_sanity_check callback\n",
    "        try:\n",
    "            assert 'latent_features' in speech.keys()\n",
    "        except:\n",
    "            print(\"No latent features passed, use BiEncoderSpeechTextModel or MultiModalSpeechTextEncoder instead.\")\n",
    "        \n",
    "        speech_representations = self.speech_model(speech)\n",
    "        text_representations = self.text_model(text).pooler_outputs\n",
    "        \n",
    "        outputs = ModelOutputs(speech_pooler_output=speech_representations, \n",
    "                               text_pooler_output=text_representations)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    \n",
    "    \n",
    "class BiEncoderSpeechTextModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pretrained_speech_model: str = 'ntu-spml/distilhubert',\n",
    "        pretrained_text_model: str = 'google/bert_uncased_L-2_H-768_A-12',\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.text_model = BertModel.from_pretrained(pretrained_text_model)\n",
    "        self.speech_model = HubertModelWithPooler(pretrained_speech_model, self.text_model.config.hidden_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, speech, text):\n",
    "        speech_representations = self.speech_model(speech)\n",
    "        text_representations = self.text_model(text).pooler_outputs\n",
    "        \n",
    "        outputs = ModelOutputs(speech_pooler_output=speech_representations, \n",
    "                               text_pooler_output=text_representations)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class MultiModalSpeechTextEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        pretrained_embedding_model: str = 'google/bert_uncased_L-8_H-256_A-4',\n",
    "        pretrained_feature_extractor_model: str = 'ntu-spml/distilhubert',\n",
    "        pretrained_transformer_model: str = 'google/bert_uncased_L-8_H-256_A-4',\n",
    "        pooler_output_size: int = 256,\n",
    "        ):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.pretrained_bert_config = PretrainedConfig.from_pretrained(pretrained_transformer_model)\n",
    "        self.pretrained_hubert_config = PretrainedConfig.from_pretrained(pretrained_feature_extractor_model)\n",
    "        \n",
    "        self.token_embedding = BertEmbeddingsWrapper.from_pretrained(pretrained_embedding_model)\n",
    "        self.feature_extractor = HubertConvFeatureExtractorWrapper.from_pretrained(pretrained_feature_extractor_model)\n",
    "        \n",
    "        if self.pretrained_bert_config.hidden_size != self.pretrained_hubert_config.hidden_size:\n",
    "            self.feature_projection = FeatureProjection(self.pretrained_hubert_config, self.pretrained_bert_config)\n",
    "        else:\n",
    "            self.feature_projection = HubertFeatureProjectionWrapper.from_pretrained(pretrained_feature_extractor_model)\n",
    "                \n",
    "        self.transformer = BertEncoderWrapper.from_pretrained(pretrained_transformer_model)\n",
    "        \n",
    "        self.speech_pooler = HubertPooler(self.pretrained_bert_config.hidden_size, pooler_output_size)\n",
    "        self.text_pooler = BertPoolerWrapper.from_pretrained(pretrained_transformer_model)\n",
    "        \n",
    "\n",
    "    def forward(self, speech, text):\n",
    "        speech_hidden_states = self.feature_extractor(speech)\n",
    "        speech_hidden_states = self.feature_projection(speech_hidden_states)\n",
    "        \n",
    "        text_hidden_states = self.token_embedding(text)\n",
    "        \n",
    "        speech_encoder_outputs = self.transformer(speech_hidden_states[0])\n",
    "        text_encoder_outputs = self.transformer(text_hidden_states)\n",
    "                \n",
    "        speech_pooler_output = self.speech_pooler(speech_encoder_outputs.last_hidden_state)\n",
    "        text_pooler_output = self.text_pooler(text_encoder_outputs.last_hidden_state)\n",
    "        \n",
    "        outputs = ModelOutputs(speech_pooler_output=speech_pooler_output, text_pooler_output=text_pooler_output)\n",
    "        \n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_enc_no_conv = BiEncoderSpeechTextModelWithoutFeatureEncoder()\n",
    "bi_enc = BiEncoderSpeechTextModel()\n",
    "mm_enc = MultiModalSpeechTextEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.children of BiEncoderSpeechTextModelWithoutFeatureEncoder(\n",
       "  (text_model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (speech_model): HubertModelWithoutFeatureEncoder(\n",
       "    (projector): HubertFeatureProjectionWrapper(\n",
       "      (feature_projection): HubertFeatureProjection(\n",
       "        (projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (encoder): HubertEncoderWrapper(\n",
       "      (encoder): HubertEncoder(\n",
       "        (pos_conv_embed): HubertPositionalConvEmbedding(\n",
       "          (conv): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "          (padding): HubertSamePadLayer()\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layers): ModuleList(\n",
       "          (0): HubertEncoderLayer(\n",
       "            (attention): HubertAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (feed_forward): HubertFeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): HubertEncoderLayer(\n",
       "            (attention): HubertAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (feed_forward): HubertFeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): HubertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_enc_no_conv.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.children of MultiModalSpeechTextEncoder(\n",
       "  (token_embedding): BertEmbeddingsWrapper(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 256, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 256)\n",
       "      (token_type_embeddings): Embedding(2, 256)\n",
       "      (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (feature_extractor): HubertConvFeatureExtractorWrapper(\n",
       "    (feature_extractor): HubertFeatureEncoder(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): HubertGroupNormConvLayer(\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "          (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (1): HubertNoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (2): HubertNoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (3): HubertNoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (4): HubertNoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (5): HubertNoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (6): HubertNoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (feature_projection): FeatureProjection(\n",
       "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (projection): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (transformer): BertEncoderWrapper(\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (speech_pooler): HubertPooler(\n",
       "    (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       "  (text_pooler): BertPoolerWrapper(\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm_enc.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertEmbeddings(\n",
       "  (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "  (position_embeddings): Embedding(512, 768)\n",
       "  (token_type_embeddings): Embedding(2, 768)\n",
       "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def freeze_layers_except_last(model, n_layers_to_train=1):\n",
    "    for name, child in model.named_children():\n",
    "        if name == 'transformer':\n",
    "            continue\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.hubert.modeling_hubert import HubertPreTrainedModel, HubertFeatureEncoder, HubertFeatureProjection, HubertEncoder, HubertPositionalConvEmbedding\n",
    "from torch.nn import LayerNorm, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters before freezing: {'requires_grad': 6.582016, 'does_not_require_grad': 12.146176}\n",
      "BertEmbeddingsWrapper\n",
      "HubertConvFeatureExtractorWrapper\n",
      "Parameters after freezing: {'requires_grad': 1.053696, 'does_not_require_grad': 17.674496}\n"
     ]
    }
   ],
   "source": [
    "def freeze_model(model, trainable_layers=0):\n",
    "    \"\"\"Trainable layers refers to the number of trainable attention layers\n",
    "        in the network. If trainable layers > 0, then the corresponding projection\n",
    "        head will also be trainable. In case of a Bi-Encoder only components of\n",
    "        speech model will be trainable, the text model will always be frozen.\n",
    "\n",
    "    Args:\n",
    "        model (\n",
    "            BiEncoderSpeechTextModelWithoutFeatureEncoder,\n",
    "            BiEncoderSpeechTextModel,\n",
    "            MultiModalSpeechTextEncoder\n",
    "            ): The model to be frozen.\n",
    "        trainablelayers (int, optional): How many attention layers in the speech or\n",
    "            multimodal encoder to train. Defaults to 0.\n",
    "    \"\"\"\n",
    "    print(f\"Parameters before freezing: {count_parameters(model)}\")\n",
    "    \n",
    "    for _, child in model.named_children():\n",
    "        \n",
    "        # standard BERT as text model\n",
    "        if isinstance(child, BertModel):\n",
    "            freeze_module(child)\n",
    "        \n",
    "        # modules for the multimodal encoder\n",
    "        elif isinstance(child, BertEmbeddingsWrapper):\n",
    "            freeze_module(child)\n",
    "        elif isinstance(child, HubertConvFeatureExtractorWrapper):\n",
    "            freeze_module(child)\n",
    "        elif isinstance(child, HubertFeatureProjectionWrapper):\n",
    "            freeze_module(child)\n",
    "        elif isinstance(child, BertEncoderWrapper):          \n",
    "            for na, ch in child.named_children():\n",
    "                for n, c in ch.named_children():\n",
    "                    if isinstance(c, torch.nn.ModuleList):\n",
    "                        for i, _ in enumerate(c._modules):\n",
    "                                if i < (len(c._modules) - trainable_layers):\n",
    "                                    freeze_module(c[i])\n",
    "        elif isinstance(child, HubertPooler) or isinstance(child, BertPoolerWrapper):\n",
    "            pass\n",
    "        \n",
    "        # modules for the speech encoder without convolution\n",
    "        elif isinstance(child, HubertModelWithoutFeatureEncoder): # done\n",
    "            for na, ch in child.named_children():\n",
    "                if isinstance(ch, HubertFeatureProjectionWrapper):\n",
    "                    freeze_module(ch)\n",
    "                elif isinstance(ch, HubertEncoderWrapper):\n",
    "                    for n, c in ch.named_children():\n",
    "                        for n_enc, c_enc in c.named_children():\n",
    "                            if isinstance(c_enc, LayerNorm):\n",
    "                                freeze_module(c_enc)\n",
    "                            elif isinstance(c_enc, Dropout):\n",
    "                                freeze_module(c_enc)\n",
    "                            elif isinstance(c_enc, torch.nn.ModuleList):\n",
    "                                for i, _ in enumerate(c_enc._modules):\n",
    "                                    if i < (len(c_enc._modules) - trainable_layers):\n",
    "                                        freeze_module(c_enc[i])\n",
    "                elif isinstance(ch, HubertPooler):\n",
    "                    pass\n",
    "        \n",
    "        # modules for the HuBERT speech encoder with convolution and pooler             \n",
    "        elif isinstance(child, HubertModelWithPooler): # done\n",
    "            for na, ch in child.named_children():\n",
    "                if isinstance(ch, HubertModel):\n",
    "                    freeze_module(ch.feature_extractor)\n",
    "                    freeze_module(ch.feature_projection)\n",
    "                    for n, c in ch.encoder.named_children():\n",
    "                        if isinstance(c, HubertPositionalConvEmbedding):\n",
    "                            freeze_module(c)\n",
    "                        elif isinstance(c, LayerNorm):\n",
    "                            freeze_module(c)\n",
    "                        elif isinstance(c, Dropout):\n",
    "                            freeze_module(c)\n",
    "                        elif isinstance(c, torch.nn.ModuleList):\n",
    "                            for i, _ in enumerate(c._modules):\n",
    "                                if i < (len(c._modules) - trainable_layers):\n",
    "                                    freeze_module(c[i])\n",
    "                if isinstance(ch, HubertPooler):\n",
    "                    pass\n",
    "                \n",
    "    print(f\"Parameters after freezing: {count_parameters(model)}\")\n",
    "    \n",
    "freeze_model(mm_enc, trainable_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiEncoderSpeechTextModel(\n",
       "  (text_model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (speech_model): HubertModelWithPooler(\n",
       "    (hubert): HubertModel(\n",
       "      (feature_extractor): HubertFeatureEncoder(\n",
       "        (conv_layers): ModuleList(\n",
       "          (0): HubertGroupNormConvLayer(\n",
       "            (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "            (activation): GELUActivation()\n",
       "            (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (1): HubertNoLayerNormConvLayer(\n",
       "            (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (2): HubertNoLayerNormConvLayer(\n",
       "            (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (3): HubertNoLayerNormConvLayer(\n",
       "            (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (4): HubertNoLayerNormConvLayer(\n",
       "            (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (5): HubertNoLayerNormConvLayer(\n",
       "            (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (6): HubertNoLayerNormConvLayer(\n",
       "            (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (feature_projection): HubertFeatureProjection(\n",
       "        (projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (encoder): HubertEncoder(\n",
       "        (pos_conv_embed): HubertPositionalConvEmbedding(\n",
       "          (conv): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "          (padding): HubertSamePadLayer()\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layers): ModuleList(\n",
       "          (0): HubertEncoderLayer(\n",
       "            (attention): HubertAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (feed_forward): HubertFeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): HubertEncoderLayer(\n",
       "            (attention): HubertAttention(\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (feed_forward): HubertFeedForward(\n",
       "              (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): HubertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2beefd3eff767b677397e49c617fe9eb55de17b3640af7353d98162718fbf92"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('speech-segment-retrieval': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
